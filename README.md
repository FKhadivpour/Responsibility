# Responsibility

## What is Responsibility?
Explainable Artificial Intelligence (XAI) methods are intended to help human users better understand and trust the decision making of an AI agent, often applied to machine learning (ML) models. Responsibility is a novel XAI approach that identifies the most responsible training instance for a particular decision. This instance can then be presented as an explanation: ``this is what I (the AI) learned that led me to do that``. 
$ Responsibility relies on altering the training process itself, to detect the training instance that maximally altered each parameter inside an ML model during training. At inference time, we can then determine the most important parameter for a particular decision, the most activated weight in the case of deep neural networks. We can then identify the training sample that maximally altered the most activated weight. We refer to this as ``\emph{the most responsible training instance}'' for the model's decision. We can then present the most responsible training instance to the human user as an answer to how the AI model learned to make that particular decision.
